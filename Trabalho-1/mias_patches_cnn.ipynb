{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3 — Patches 32×32, Balanceamento e CNN (mini-MIAS)\n",
        "\n",
        "Este notebook continua o pipeline após o **Notebook 2 (equalização)**.\n",
        "\n",
        "## Objetivos\n",
        "1. **Carregar** as imagens **equalizadas** (ou pré-processadas) e seus metadados;\n",
        "2. **Extrair patches** de tamanho **32×32** com `stride` configurável, usando a máscara para evitar fundo;\n",
        "3. **Atribuir rótulos** por `SEVERITY` (Normal/Benign/Malignant) a partir do `preprocess_manifest.csv`;\n",
        "4. **Balancear** o dataset por classe usando **undersampling** até o tamanho da classe minoritária;\n",
        "5. **Split por REFNUM** (70/15/15) para evitar *data leakage* entre patches da mesma imagem;\n",
        "6. **Treinar uma CNN** simples (Keras) e **avaliar** com Accuracy, Precision, Recall, F1 e **matriz de confusão**.\n",
        "\n",
        "### Pré-requisitos\n",
        "- Notebook 1: `outputs_preproc/` existente (imagens e máscaras)\n",
        "- Notebook 2: `outputs_eq/<modo>/` existente com as equalizações ou usar as pré-processadas\n",
        "- `outputs_preproc/preprocess_manifest.csv` gerado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando equalização: clahe_test6\n"
          ]
        }
      ],
      "source": [
        "# ==== Configurações principais ====\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path('.')\n",
        "PREPROC_DIR = BASE_DIR / 'outputs_preproc'\n",
        "PREPROC_IMG_DIR = PREPROC_DIR / 'images'\n",
        "PREPROC_MSK_DIR = PREPROC_DIR / 'masks'\n",
        "PREPROC_MANIFEST = PREPROC_DIR / 'preprocess_manifest.csv'\n",
        "\n",
        "# Use um dos modos abaixo gerados pelo Notebook 2, ou defina None para usar imagens pré-processadas\n",
        "EQUALIZATION_MODE = 'clahe_test6'   # opções: 'hiw_test1','hiw_test2','hiw_test3','clahe_test5','clahe_test6' ou None\n",
        "EQ_DIR = BASE_DIR / 'outputs_eq' / EQUALIZATION_MODE if EQUALIZATION_MODE else None\n",
        "\n",
        "# Extração de patches\n",
        "PATCH_SIZE = 32\n",
        "STRIDE = 32   # 16 para overlaps\n",
        "MASK_MIN_FRACTION = 0.6  # fração mínima de pixels da mama dentro do patch\n",
        "\n",
        "# Split por REFNUM (evita vazamento)\n",
        "SPLIT = {'train': 0.70, 'val': 0.15, 'test': 0.15}\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Treino\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "LR = 1e-3\n",
        "\n",
        "print('Usando equalização:', EQUALIZATION_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==== Imports ====\n",
        "import os, re, glob, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==== Utilidades ====\n",
        "def read_gray_float01(path: Path):\n",
        "    img = io.imread(path)\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    img = img.astype(np.float32)\n",
        "    if img.max() > 1:\n",
        "        img = img / 255.0\n",
        "    return np.clip(img, 0.0, 1.0)\n",
        "\n",
        "def extract_refnum(filename:str):\n",
        "    base = os.path.basename(filename).lower()\n",
        "    m = re.search(r\"(mdb\\d{3})\", base)\n",
        "    return m.group(1) if m else os.path.splitext(base)[0]\n",
        "\n",
        "def ensure_dir(p: Path):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def as_uint8(img):\n",
        "    return (np.clip(img, 0, 1) * 255 + 0.5).astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Carregar manifest e decidir a origem das imagens\n",
        "- Se `EQUALIZATION_MODE` for definido, vamos ler as imagens em `outputs_eq/<modo>/`.\n",
        "- Caso contrário, usaremos as imagens pré-processadas em `outputs_preproc/images/`.\n",
        "- Para filtrar patches, usamos a **máscara** correspondente de `outputs_preproc/masks/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linhas no manifest: 644\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REFNUM</th>\n",
              "      <th>output_img</th>\n",
              "      <th>output_mask</th>\n",
              "      <th>SEVERITY</th>\n",
              "      <th>DENSITY</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>CLASS_GROUP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>outputs_preproc\\images\\mdb001_preproc.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb001_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>outputs_preproc\\images\\mdb001_preproc.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb001_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mdb002</td>\n",
              "      <td>outputs_preproc\\images\\mdb002_preproc.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb002_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   REFNUM                                 output_img  \\\n",
              "0  mdb001  outputs_preproc\\images\\mdb001_preproc.png   \n",
              "1  mdb001  outputs_preproc\\images\\mdb001_preproc.png   \n",
              "2  mdb002  outputs_preproc\\images\\mdb002_preproc.png   \n",
              "\n",
              "                             output_mask SEVERITY DENSITY CLASS CLASS_GROUP  \n",
              "0  outputs_preproc\\masks\\mdb001_mask.png   Benign       B  CIRC      Masses  \n",
              "1  outputs_preproc\\masks\\mdb001_mask.png   Benign       B  CIRC      Masses  \n",
              "2  outputs_preproc\\masks\\mdb002_mask.png   Benign       B  CIRC      Masses  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assert PREPROC_MANIFEST.is_file(), f\"Manifest não encontrado: {PREPROC_MANIFEST}\"\n",
        "meta = pd.read_csv(PREPROC_MANIFEST)\n",
        "\n",
        "# Ajusta REFNUM para minúsculas\n",
        "meta['REFNUM'] = meta['REFNUM'].astype(str).str.lower()\n",
        "\n",
        "# Seleciona apenas colunas relevantes\n",
        "cols = ['REFNUM','output_img','output_mask','SEVERITY','DENSITY','CLASS','CLASS_GROUP']\n",
        "for c in cols:\n",
        "    if c not in meta.columns:\n",
        "        meta[c] = np.nan\n",
        "meta = meta[cols]\n",
        "\n",
        "print('Linhas no manifest:', len(meta))\n",
        "meta.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Montar lista de caminhos de imagem de **entrada do modelo**\n",
        "Se houver equalização escolhida, substituímos o caminho da imagem pelo arquivo correspondente em `outputs_eq/<modo>/` mantendo o `REFNUM` no nome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imagens utilizáveis: 644\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REFNUM</th>\n",
              "      <th>img_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>SEVERITY</th>\n",
              "      <th>DENSITY</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>CLASS_GROUP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>outputs_eq\\clahe_test6\\mdb001_clahe_test6.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb001_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>outputs_eq\\clahe_test6\\mdb001_clahe_test6.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb001_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mdb002</td>\n",
              "      <td>outputs_eq\\clahe_test6\\mdb002_clahe_test6.png</td>\n",
              "      <td>outputs_preproc\\masks\\mdb002_mask.png</td>\n",
              "      <td>Benign</td>\n",
              "      <td>B</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>Masses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   REFNUM                                       img_path  \\\n",
              "0  mdb001  outputs_eq\\clahe_test6\\mdb001_clahe_test6.png   \n",
              "1  mdb001  outputs_eq\\clahe_test6\\mdb001_clahe_test6.png   \n",
              "2  mdb002  outputs_eq\\clahe_test6\\mdb002_clahe_test6.png   \n",
              "\n",
              "                               mask_path SEVERITY DENSITY CLASS CLASS_GROUP  \n",
              "0  outputs_preproc\\masks\\mdb001_mask.png   Benign       B  CIRC      Masses  \n",
              "1  outputs_preproc\\masks\\mdb001_mask.png   Benign       B  CIRC      Masses  \n",
              "2  outputs_preproc\\masks\\mdb002_mask.png   Benign       B  CIRC      Masses  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def eq_path_for_ref(refnum: str, mode: str):\n",
        "    if not mode:\n",
        "        return None\n",
        "    # Saída do Notebook 2 salva como: <ref>_<modo>.png (onde <ref> é stem sem _preproc)\n",
        "    # Ex.: mdb001_clahe_test6.png\n",
        "    return (EQ_DIR / f\"{refnum}_{mode}.png\")\n",
        "\n",
        "def build_records(meta_df: pd.DataFrame, mode: str):\n",
        "    recs = []\n",
        "    for _, row in meta_df.iterrows():\n",
        "        ref = row['REFNUM']\n",
        "        mask_path = Path(row['output_mask']) if isinstance(row['output_mask'], str) else None\n",
        "        if mode:\n",
        "            img_path = eq_path_for_ref(ref, mode)\n",
        "        else:\n",
        "            # usa a pré-processada\n",
        "            img_path = Path(str(row['output_img']).replace('_preproc.png', '_preproc.png'))\n",
        "        recs.append({\n",
        "            'REFNUM': ref,\n",
        "            'img_path': str(img_path) if img_path else None,\n",
        "            'mask_path': str(mask_path) if mask_path else None,\n",
        "            'SEVERITY': row['SEVERITY'],\n",
        "            'DENSITY': row['DENSITY'],\n",
        "            'CLASS': row['CLASS'],\n",
        "            'CLASS_GROUP': row['CLASS_GROUP'],\n",
        "        })\n",
        "    df = pd.DataFrame(recs)\n",
        "    # Mantém somente registros existentes em disco\n",
        "    df = df[df['img_path'].apply(lambda p: Path(p).is_file())]\n",
        "    df = df[df['mask_path'].apply(lambda p: Path(p).is_file())]\n",
        "    return df\n",
        "\n",
        "df_img = build_records(meta, EQUALIZATION_MODE)\n",
        "print('Imagens utilizáveis:', len(df_img))\n",
        "df_img.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Extração de patches 32×32\n",
        "- Deslizamos janelas 32×32 com `stride` definido;\n",
        "- Filtramos por **máscara** (mínimo `MASK_MIN_FRACTION` de pixels da mama dentro do patch);\n",
        "- Atribuímos o rótulo de **SEVERITY** do `REFNUM`.\n",
        "\n",
        "> Dica: você pode ajustar `STRIDE` (ex.: 16) para aumentar a amostra, mantendo o split por REFNUM para não vazar entre conjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de patches extraídos: 452326\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SEVERITY\n",
              "Normal                                                                                         291920\n",
              "Benign                                                                                          83180\n",
              "Malignant                                                                                       67248\n",
              "REFNUM\\nmdb249    Malignant\\nmdb249    Malignant\\nName: SEVERITY, dtype: object                  1710\n",
              "REFNUM\\nmdb144       Benign\\nmdb144    Malignant\\nName: SEVERITY, dtype: object                  1630\n",
              "REFNUM\\nmdb005    Benign\\nmdb005    Benign\\nName: SEVERITY, dtype: object                        1616\n",
              "REFNUM\\nmdb239    Malignant\\nmdb239    Malignant\\nName: SEVERITY, dtype: object                  1536\n",
              "REFNUM\\nmdb226    Benign\\nmdb226    Benign\\nmdb226    Benign\\nName: SEVERITY, dtype: object      1280\n",
              "REFNUM\\nmdb223    Benign\\nmdb223    Benign\\nName: SEVERITY, dtype: object                        1190\n",
              "REFNUM\\nmdb132    Benign\\nmdb132    Benign\\nName: SEVERITY, dtype: object                        1016\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def extract_patches_from_image(img, msk, patch=32, stride=32, mask_min_fraction=0.6):\n",
        "    H, W = img.shape\n",
        "    patches = []\n",
        "    for y in range(0, H - patch + 1, stride):\n",
        "        for x in range(0, W - patch + 1, stride):\n",
        "            roi = img[y:y+patch, x:x+patch]\n",
        "            rmask = msk[y:y+patch, x:x+patch]\n",
        "            if rmask.mean() >= mask_min_fraction:\n",
        "                patches.append((roi, (y, x)))\n",
        "    return patches\n",
        "\n",
        "records = []\n",
        "for _, r in df_img.iterrows():\n",
        "    img = read_gray_float01(Path(r['img_path']))\n",
        "    msk = read_gray_float01(Path(r['mask_path']))\n",
        "    msk = (msk > 0.5).astype(np.float32)\n",
        "    pts = extract_patches_from_image(img, msk, PATCH_SIZE, STRIDE, MASK_MIN_FRACTION)\n",
        "    for roi, (yy, xx) in pts:\n",
        "        records.append({\n",
        "            'REFNUM': r['REFNUM'],\n",
        "            'SEVERITY': r['SEVERITY'],\n",
        "            'patch': roi.astype(np.float32),\n",
        "        })\n",
        "\n",
        "df_patches = pd.DataFrame(records)\n",
        "print('Total de patches extraídos:', len(df_patches))\n",
        "df_patches['SEVERITY'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Split por REFNUM e balanceamento por classe\n",
        "- Split estratificado **por imagem** (REFNUM) em 70/15/15;\n",
        "- Em seguida, **undersampling** no nível de **patches** para igualar as classes ao **mínimo** disponível."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patches por split (antes do balanceamento):\n",
            "train: {'Normal': 203358, 'Benign': 57138, 'Malignant': 47842}\n",
            "val  : {'Normal': 43672, 'Benign': 12132, 'Malignant': 9170}\n",
            "test : {'Normal': 44890, 'Benign': 13910, 'Malignant': 10236, 'REFNUM\\nmdb249    Malignant\\nmdb249    Malignant\\nName: SEVERITY, dtype: object': 1710, 'REFNUM\\nmdb144       Benign\\nmdb144    Malignant\\nName: SEVERITY, dtype: object': 1630, 'REFNUM\\nmdb005    Benign\\nmdb005    Benign\\nName: SEVERITY, dtype: object': 1616, 'REFNUM\\nmdb239    Malignant\\nmdb239    Malignant\\nName: SEVERITY, dtype: object': 1536, 'REFNUM\\nmdb226    Benign\\nmdb226    Benign\\nmdb226    Benign\\nName: SEVERITY, dtype: object': 1280, 'REFNUM\\nmdb223    Benign\\nmdb223    Benign\\nName: SEVERITY, dtype: object': 1190, 'REFNUM\\nmdb132    Benign\\nmdb132    Benign\\nName: SEVERITY, dtype: object': 1016}\n",
            "\n",
            "Patches por split (após balanceamento):\n",
            "train: {'Malignant': 47842, 'Benign': 47842, 'Normal': 47842}\n",
            "val  : {'Benign': 9170, 'Malignant': 9170, 'Normal': 9170}\n",
            "test : {'REFNUM\\nmdb249    Malignant\\nmdb249    Malignant\\nName: SEVERITY, dtype: object': 1016, 'REFNUM\\nmdb005    Benign\\nmdb005    Benign\\nName: SEVERITY, dtype: object': 1016, 'Malignant': 1016, 'Normal': 1016, 'REFNUM\\nmdb239    Malignant\\nmdb239    Malignant\\nName: SEVERITY, dtype: object': 1016, 'REFNUM\\nmdb226    Benign\\nmdb226    Benign\\nmdb226    Benign\\nName: SEVERITY, dtype: object': 1016, 'Benign': 1016, 'REFNUM\\nmdb144       Benign\\nmdb144    Malignant\\nName: SEVERITY, dtype: object': 1016, 'REFNUM\\nmdb223    Benign\\nmdb223    Benign\\nName: SEVERITY, dtype: object': 1016, 'REFNUM\\nmdb132    Benign\\nmdb132    Benign\\nName: SEVERITY, dtype: object': 1016}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Mapeia cada REFNUM para sua classe (SEVERITY)\n",
        "ref2label = df_patches.groupby('REFNUM')['SEVERITY'].agg(lambda s: s.iloc[0]).to_dict()\n",
        "\n",
        "# Lista de REFNUM por classe\n",
        "by_class_refs = defaultdict(list)\n",
        "for ref, lab in ref2label.items():\n",
        "    by_class_refs[str(lab)].append(ref)\n",
        "\n",
        "train_refs, val_refs, test_refs = set(), set(), set()\n",
        "rng = np.random.RandomState(RANDOM_SEED)\n",
        "for lab, refs in by_class_refs.items():\n",
        "    refs = sorted(refs)\n",
        "    rng.shuffle(refs)\n",
        "    n = len(refs)\n",
        "    n_train = int(SPLIT['train'] * n)\n",
        "    n_val = int(SPLIT['val'] * n)\n",
        "    train_refs.update(refs[:n_train])\n",
        "    val_refs.update(refs[n_train:n_train+n_val])\n",
        "    test_refs.update(refs[n_train+n_val:])\n",
        "\n",
        "def subset_by_refs(df, refs):\n",
        "    return df[df['REFNUM'].isin(refs)].copy()\n",
        "\n",
        "train_df = subset_by_refs(df_patches, train_refs)\n",
        "val_df   = subset_by_refs(df_patches, val_refs)\n",
        "test_df  = subset_by_refs(df_patches, test_refs)\n",
        "\n",
        "print('Patches por split (antes do balanceamento):')\n",
        "print('train:', train_df['SEVERITY'].value_counts(dropna=False).to_dict())\n",
        "print('val  :', val_df['SEVERITY'].value_counts(dropna=False).to_dict())\n",
        "print('test :', test_df['SEVERITY'].value_counts(dropna=False).to_dict())\n",
        "\n",
        "def undersample_to_min(df, label_col='SEVERITY'):\n",
        "    counts = df[label_col].value_counts()\n",
        "    if len(counts) == 0:\n",
        "        return df\n",
        "    min_count = counts.min()\n",
        "    parts = []\n",
        "    for lab, c in counts.items():\n",
        "        part = df[df[label_col] == lab].sample(min_count, random_state=RANDOM_SEED)\n",
        "        parts.append(part)\n",
        "    out = pd.concat(parts, axis=0).sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "train_df_bal = undersample_to_min(train_df)\n",
        "val_df_bal   = undersample_to_min(val_df)\n",
        "test_df_bal  = undersample_to_min(test_df)\n",
        "\n",
        "print('\\nPatches por split (após balanceamento):')\n",
        "print('train:', train_df_bal['SEVERITY'].value_counts(dropna=False).to_dict())\n",
        "print('val  :', val_df_bal['SEVERITY'].value_counts(dropna=False).to_dict())\n",
        "print('test :', test_df_bal['SEVERITY'].value_counts(dropna=False).to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Preparar tensores e rótulos (LabelEncoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes (ordem do encoder): ['Benign', 'Malignant', 'Normal']\n",
            "Classes (ordem do encoder): ['Benign', 'Malignant', 'Normal']\n",
            "Shapes: (143526, 32, 32, 1) (27510, 32, 32, 1) (10160, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def clean_severity(v):\n",
        "    # Caso seja uma Series/array/objeto com iloc, pega o primeiro elemento\n",
        "    if hasattr(v, \"iloc\"):\n",
        "        try:\n",
        "            v = v.iloc[0]\n",
        "        except Exception:\n",
        "            v = str(v)\n",
        "    if isinstance(v, (list, tuple, np.ndarray)):\n",
        "        v = v[0] if len(v) else \"\"\n",
        "    # string pura, sem quebras de linha / rótulos anexos\n",
        "    v = str(v)\n",
        "    v = v.replace(\"\\n\", \" \").strip()\n",
        "    # normaliza capitalização e mapeia variações\n",
        "    vl = v.lower()\n",
        "    if \"normal\" in vl:\n",
        "        return \"Normal\"\n",
        "    if \"benign\" in vl:   # pega 'benign'/'benigno'\n",
        "        return \"Benign\"\n",
        "    if \"malig\" in vl:    # pega 'malig'/'malignant'/'maligno'\n",
        "        return \"Malignant\"\n",
        "    # fallback\n",
        "    return v or \"Unknown\"\n",
        "\n",
        "# 2) Aplica limpeza nos três splits ANTES de treinar o encoder\n",
        "for _df in [train_df_bal, val_df_bal, test_df_bal]:\n",
        "    _df[\"SEVERITY\"] = _df[\"SEVERITY\"].apply(clean_severity).astype(str)\n",
        "\n",
        "# 3) Treina o encoder só com as classes presentes no TREINO\n",
        "le = LabelEncoder()\n",
        "le.fit(train_df_bal[\"SEVERITY\"].values)\n",
        "n_classes = len(le.classes_)\n",
        "print(\"Classes (ordem do encoder):\", list(le.classes_))\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_df_bal['SEVERITY'].astype(str).values)\n",
        "n_classes = len(le.classes_)\n",
        "print('Classes (ordem do encoder):', list(le.classes_))\n",
        "\n",
        "def df_to_xy(df):\n",
        "    # Garante que haverá ao menos 1 amostra antes de empilhar\n",
        "    if len(df) == 0:\n",
        "        return np.empty((0, PATCH_SIZE, PATCH_SIZE, 1), dtype=np.float32), np.empty((0,), dtype=np.int64)\n",
        "    X = np.stack(df['patch'].values).astype(np.float32)\n",
        "    X = X[..., np.newaxis]  # (N, 32, 32, 1)\n",
        "    y = le.transform(df['SEVERITY'].astype(str).values)\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = df_to_xy(train_df_bal)\n",
        "X_val,   y_val   = df_to_xy(val_df_bal)\n",
        "X_test,  y_test  = df_to_xy(test_df_bal)\n",
        "\n",
        "print('Shapes:', X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) CNN simples (Keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jhter\\OneDrive - cefet-rj.br\\Processamento-Imagem\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,331</span> (1.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m355,331\u001b[0m (1.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,331</span> (1.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m355,331\u001b[0m (1.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def build_cnn(input_shape=(32,32,1), n_classes=3):\n",
        "    m = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "model = build_cnn(input_shape=(PATCH_SIZE,PATCH_SIZE,1), n_classes=n_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 11ms/step - accuracy: 0.3342 - loss: 1.0988 - val_accuracy: 0.3333 - val_loss: 1.0987 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.3308 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0987 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.3322 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0987 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m2242/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3340 - loss: 1.0986\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.3320 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0987 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3325 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - accuracy: 0.3319 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m2242/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3328 - loss: 1.0986\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3320 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3334 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3329 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m2241/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3334 - loss: 1.0986\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.3329 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - accuracy: 0.3317 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 1.2500e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.3324 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 1.2500e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m2242/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3313 - loss: 1.0986\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.3321 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.3325 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 6.2500e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3326 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 6.2500e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m2241/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3323 - loss: 1.0986\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m2243/2243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.3325 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986 - learning_rate: 6.2500e-05\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Avaliação — métricas e matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Relatório de classificação (por patches):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.00      0.00      0.00      6096\n",
            "   Malignant       0.30      1.00      0.46      3048\n",
            "      Normal       0.00      0.00      0.00      1016\n",
            "\n",
            "    accuracy                           0.30     10160\n",
            "   macro avg       0.10      0.33      0.15     10160\n",
            "weighted avg       0.09      0.30      0.14     10160\n",
            "\n",
            "Matriz de confusão (ordem dos rótulos = encoder):\n",
            "[[   0 6096    0]\n",
            " [   0 3048    0]\n",
            " [   0 1016    0]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test, batch_size=BATCH_SIZE)\n",
        "y_hat = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Para evitar erro quando alguma classe não aparece no y_test,\n",
        "# fixamos o conjunto de labels e target_names de acordo com o encoder\n",
        "all_labels = np.arange(n_classes)\n",
        "all_names  = list(le.classes_)\n",
        "\n",
        "print('Relatório de classificação (por patches):')\n",
        "print(classification_report(\n",
        "    y_test, y_hat,\n",
        "    labels=all_labels,\n",
        "    target_names=all_names,\n",
        "    zero_division=0  # evita warnings/erros de divisão por zero\n",
        "))\n",
        "\n",
        "# Matriz de confusão com eixo fixo (inclui classes ausentes no teste)\n",
        "cm = confusion_matrix(y_test, y_hat, labels=all_labels)\n",
        "print('Matriz de confusão (ordem dos rótulos = encoder):')\n",
        "print(cm)\n",
        "\n",
        "# Plot da matriz (sem especificar cores)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(cm, aspect='auto')\n",
        "plt.title('Matriz de Confusão (patches)')\n",
        "plt.xlabel('Predito')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xticks(ticks=all_labels, labels=all_names, rotation=45)\n",
        "plt.yticks(ticks=all_labels, labels=all_names)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Observações\n",
        "- O artigo reporta métricas por **conjuntos de imagens** e também efeitos por **grupos de lesões**; aqui avaliamos por **patches**. Se quiser, agregue por **imagem** (voto da maioria dos patches) para aproximar do nível de imagem;\n",
        "- Ajuste `STRIDE` para controlar o nº de patches. `16` tende a aumentar o dataset, mas mantenha o split por **REFNUM**;\n",
        "- Para usar **outra equalização**, altere `EQUALIZATION_MODE` (conforme Notebook 2);\n",
        "- Você pode trocar a CNN por uma arquitetura um pouco maior (BatchNorm, mais camadas) para tentar reproduzir os números do paper;\n",
        "- Caso queira estratificar por **DENSITY**/`BI-RADS`, basta filtrar `df_img`/`df_patches` antes de extrair os conjuntos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
